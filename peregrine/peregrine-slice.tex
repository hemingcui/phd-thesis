\section{Determinism-Preserving Slicing} \label{sec:peregrine-slice}

\peregrine uses determinism-preserving slicing to (1) compute sufficient
preconditions to avoid new races and ensure that a schedule is feasible,
and (2) filter many unnecessary preconditions to increase schedule-reuse
rates.  It does so using inter- and intra-thread steps.  In the
inter-thread step (\S\ref{sec:peregrine-interthread-slice}), it detects and avoids
\emph{input-dependent} races that do not occur in the execution trace, but
may occur if we reuse the schedule on a different input.
In the intra-thread step (\S\ref{sec:peregrine-interthread-slice}), the analyzer
computes a \emph{path slice} per thread by including instructions that may
affect the events in the schedule or the instructions identified in the
inter-thread step.


\subsection{Inter-thread Step} \label{sec:peregrine-interthread-slice}

In the inter-thread step, \peregrine detects and avoids input-dependent races
with respect to a hybrid schedule.  An example input-dependent race is the
one between lines L8 and L15 in Figure~\ref{fig:peregrine-example}, which occurs when
\vv{atoi(argv[3])} returns 1 causing the true branch of L7 to be taken.
Figure~\ref{fig:peregrine-input-race-examples} shows two more types of input-dependent races.

\begin{figure}[b]
\vspace{-.1in}
\centering
\hspace{\stretch{1}}
\begin{minipage}[b]{.225\textwidth}
  \lgrindfile{peregrine/code/not-run.cpp.tex}
  \center{\vskip -3mm \hskip -5mm \scriptsize \bf (a)}
\end{minipage}
\hspace{\stretch{1}}
\begin{minipage}[b]{.225\textwidth}
  \lgrindfile{peregrine/code/br-br.cpp.tex}
  \center{\vskip -3mm \hskip -5mm \scriptsize \bf (b)}
\end{minipage}
\hspace{\stretch{1}}
\vspace{-.1in}
\caption{{\em Input-dependent races.} Race (a) occurs when
  \vv{input1} and \v{input2} are the same; Race (b) occurs when
  both true branches are taken.} \label{fig:peregrine-input-race-examples}
\end{figure}

To detect such races, \peregrine starts by refining the logical clocks computed
based on the sync-schedule (\S\ref{sec:peregrine-compute-schedule}) with
execution order constraints because it will also enforce these
constraints.  \peregrine then iterates through all pairs
of concurrent \emph{regions}, where a region is a set of instructions with an identical
logical clock.  For each pair, it detects input-dependent races, and adds
the racy instructions to a list of \emph{slicing targets} used by the
intra-thread step.

\begin{figure}[!ht]
%%\centering
\vspace{-.3in}
\begin{minipage}[t]{\textwidth}
\tiny  \lgrindfile{peregrine/code/input-race.cpp.tex}
\end{minipage}
\vspace{-.2in}
\caption{{\em Input-dependent race detection
    algorithm.}} \label{fig:peregrine-detect-input-race}
\vspace{-.1in}
\end{figure}

Figure~\ref{fig:peregrine-detect-input-race} shows the algorithm to detect
input-dependent races for two concurrent regions.  The algorithm iterates
through each pair of instructions respectively from the
two regions, and handles three types of input-dependent races.  First, if
neither instruction is a branch instruction, it queries alias analysis to
determine whether the instructions \emph{may} race.  If so, it adds both
instructions to \vv{slicing\_targets} and adds additional
preconditions to ensure that the pointers dereferenced are different, so
that reusing the schedule on a different input does not cause the may-race
to become a real race.  Figure~\ref{fig:peregrine-input-race-examples}(a) shows
a race of this type.

Second, if exactly one of the instructions is a branch instruction, the
algorithm checks whether the instructions contained in the not-taken
branch\footnote{\peregrine computes instructions contained in a not-taken
  branch using an interprocedural \emph{post-dominator
    analysis}~\cite{aho:dragon:06}.} of this instruction may race with the
other instruction.
It must check the not-taken branch because a new
execution may well take the not-taken branch and cause a race.  To avoid such a
race, \peregrine adds the taken branch into the trace slice so that executions
reusing the schedule always go down the taken branch.  For instance, to
avoid the input-dependent race between lines L8 and L15
in Figure~\ref{fig:peregrine-example}, \peregrine includes
the false branch of L7 in the trace slice.

Third, if both instructions are branch instructions, the algorithm checks
whether the not-taken branches of the instructions may race, and if so, it
adds either taken branch to \vv{slicing\_targets}.
For instance, to avoid the race in Figure~\ref{fig:peregrine-input-race-examples}(b),
\peregrine includes one of the false branches in the trace slice.

For efficiency, \peregrine avoids iterating through all pairs of instructions
from two concurrent regions because instructions in one region often
repeatedly access the same memory locations.  Thus, \peregrine computes memory
locations read or written by all instructions in one region, then checks
whether instructions in the other region also read or write these memory
locations.  These locations are static operands, not dynamic
addresses~\cite{rwset:tacas08}, so that \peregrine can aggressively cache them
per static function or branch.  The complexity of our algorithm thus drops from
$O(MN)$ to $O(M+N)$ where $M$ and $N$ are the numbers of memory
instructions in the two regions respectively.


\subsection{Intra-thread Step} \label{sec:peregrine-intrathread-slice}

In the intra-thread step, \peregrine leverages a previous
algorithm~\cite{castro:bouncer} to compute a per-thread path slice,
by including instructions required for the thread to reach the
\vv{slicing\_targets} identified in the inter-thread step and the events in
the hybrid schedule.  To do so, \peregrine first prepares a per-thread ordered
target list by splitting \vv{slicing\_targets} and events in the hybrid
schedule and sorting them based on their order in the execution trace.

\peregrine then traverses the execution trace backwards to compute path slices.
When it sees a target, it adds the target to the path slice of the
corresponding thread, and starts to track the control- and
data-dependencies of this target.\footnote{For readers familiar with
  precondition slicing, \peregrine does not always track data-dependencies for
  the operands of a target.  For instance, consider instruction
  L9 of thread $t_0$ in Figure~\ref{fig:peregrine-trace}.  \peregrine's goal is
  to deterministically resolve the race involving L9 of $t_0$, but it
  allows the value of \vv{result} to be different.  Thus, \peregrine does not
  track dependencies for the value of \vv{result}; L15 of $t_0$ is elided
  from the slice for this reason.}  \peregrine adds a branch
instruction to the path slice if taking the opposite branch may cause the
thread not to reach any instruction in the current (partial) path slice;
L3 in Figure~\ref{fig:peregrine-trace} is added for this reason.
It adds a non-branch instruction to the path slice if the result of this
instruction may be used by instructions in the current path slice;
L1 in Figure~\ref{fig:peregrine-trace} is added for this reason.

A ``\vv{load p}'' instruction may depend on an earlier ``\vv{store q}'' if
\vv{p} and \vv{q} may alias even though \vv{p} and \vv{q} may not be the
same in the execution trace, because an execution on a different input
may cause \vv{p} and \v{q} to be the same.  Thus, \peregrine queries alias
analysis to compute such \emph{may}-dependencies and include the depended-upon
instructions in the trace slice.

Our main modification to~\cite{castro:bouncer} is to slice toward multiple
ordered targets.  To illustrate this need, consider branch L4:false of
$t_0$ in Figure~\ref{fig:peregrine-trace}.  \peregrine must add this branch  to thread
$t_0$'s slice, because otherwise, the thread would reach another
\vv{pthread\_create()}, a different synchronization operation than the
\vv{pthread\_mutex\_lock()} operation in the schedule.


The choice of LLVM IR has considerably simplified our slicing
implementation.  First, LLVM IR limits memory access to only two
instructions, \vv{load} and \vv{store}, so that our
algorithms need consider only these
instructions.  Second, LLVM IR uses an unlimited number of virtual registers,
so that our analysis does not get poisoned by stack spilling instructions.
Third, each virtual register is defined exactly once, and multiple
definitions to a variable are merged using a special instruction.  This
representation (\emph{static single assignment}) simplifies
control- and data-dependency tracking.  Lastly, the type information LLVM IR
preserves helps improving the precision of the alias analysis.

