\subsubsection{Efficiently Enforcing Schedules} \label{sec:relax}

%% challenge 1: dmt race \vs overhead
%% challenge 2: manual annotation
%% insight: can detect race, and compute precond, detect races in memoized
%%          schedules, and enforce races later.
%% key idea of the slicing algorithm
%% results: overhead

Prior work enforces schedules at two different granularities: shared
memory accesses or synchronizations, forcing users to trade off efficiency
and determinism.  Specifically, memory access schedules make data races
deterministic but are prohibitively inefficient (\eg, 1.2X-6X as slow as
traditional multithreading~\cite{coredet:asplos10}); synchronization
schedules are much more efficient (\eg, average 16\%
slowdown~\cite{kendo:asplos09}) because they are coarse grained, but they
cannot make programs with data races deterministic, such as our second toy
program in \S\ref{sec:why} and many real-world multithreaded
programs~\cite{lu:concurrency-bugs,syncfinder:osdi10}.  This determinism
\vs performance challenge has been open for decades in the areas of
deterministic execution and replay.  Because of this challenge, 
\tern, our first \smt system, enforces only synchronization schedules.


\begin{figure}[t]
\includegraphics[width=\linewidth]{peregrine/figures/hybrid-schedule}
\vspace{-.3in}
\caption{{\em Hybrid schedule idea.} Circles represent synchronizations,
  and triangles memory accesses.  A synchronization schedule is efficient
  because it is coarse-grained, but it is not deterministic because data
  races may still cause executions to deviate from the schedule and
  fail.  A memory access schedule is
  deterministic, but it is slow because it is fine-grained.  A hybrid
  schedule combines the best of both by scheduling memory access only for
  the racy portion of an execution and synchronizations
  otherwise.} \label{fig:hybrid-schedule}
\end{figure}

To address this challenge, we have built \peregrine, our second \smt
system~\cite{peregrine:sosp11}.  The insight in \peregrine is that although
many programs have races, the races tend to occur only within small
portions of an execution, and the majority of the execution is still
race-free.  Intuitively, if a program is full of data races, most of them
would have been caught during testing.  Empirically, we analyzed the
executions of seven real programs with races, and found that, despite
millions of memory accesses, only up to 10 data races were detected per
execution.

Since races occur rarely, we can schedule synchronizations for the
race-free portions of an execution, and resort to scheduling memory
accesses only for the ``racy'' portions, combining both the efficiency of
synchronization schedules and the determinism of memory access schedules.
These hybrid schedules are almost as coarse-grained as synchronization
schedules, so they can also be frequently reused.  
Figure~\ref{fig:hybrid-schedule} illustrates this idea.

How can we predict where data races may occur before an execution actually
starts?  One possible idea is to use static analysis to detect data races
at compile time.
%  and treat the offending load and store instructions as synchronizations.
However, static race detectors are notoriously imprecise: a majority of
their reports tend to be false reports, not true data races.  Scheduling
many memory accesses in the false reports would severely slow down the
execution.

\peregrine leverages the record-and-reuse approach in \tern to predict races:
a recorded execution can effectively foretell what may happen for
executions reusing the same schedule.  Specifically, when recording a
synchronization schedule, \peregrine records a detailed memory access trace.
From the trace, it detects data races that occurred (with respect to the
schedule), and adds the memory accesses involved in the races to the
schedule.  Now, this hybrid schedule can be efficiently and
deterministically enforced, solving the aforementioned open challenge.
To reuse the schedule on other inputs, \peregrine provides new precondition
computation algorithms to guarantee that executions reusing the schedule
will not run into any new data races. To enforce an order on memory
accesses, \peregrine modifies a live program at runtime using
a safe, efficient instrumentation framework we built~\cite{wu:loom:osdi10}.
