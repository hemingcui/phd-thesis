\section{Refinements} \label{sec:tern-impl}

This section describes four refinements we made, one for
determinism (\S\ref{sec:tern-detect-race}) and three for speed
(\S\ref{sec:tern-skip-waits}-\S\ref{sec:tern-slicing}).

\subsection{Detecting Data Races} \label{sec:tern-detect-race}

%%\capstartfalse
\begin{figure}
\begin{minipage}[t]{0.45\linewidth}
\tiny
\lgrindfile{tern/code/avoided-race.cpp}
\caption{\small\em A conventional race, not a schedule race.}
\label{fig:tern-avoided-race}
\end{minipage}
\hfill
\begin{minipage}[t]{0.48\linewidth}
\tiny 
\lgrindfile{tern/code/symbolic-race.cpp}
\vspace{-.2in}
\caption{\small\em A symbolic race that occurs only when $i=j$.}
\label{fig:tern-symbolic-race}
\end{minipage}
\vspace{-.2in}
\end{figure}
%%\capstarttrue

As discussed in \S\ref{sec:tern-define-schedule}, if a memoized schedule allows
data races, runs reusing this schedule may become nondeterministic.  Thus,
for determinism, we would like to detect races in memoized schedules and
discard them from the schedule cache.  A general race detector would flag
too many races for \tern because it detects conventional races with respect
to the original synchronization constraints of the program, whereas we
want to detect races with respect to the order constraints of a
schedule~\cite{recplay:tocs} (call them \emph{schedule races}).
Figure~\ref{fig:tern-avoided-race} shows a conventional race, but not a
schedule race because the synchronization order shown ``kills'' the race.

Thus, we built a simple race detector to detect schedule races.  It runs
with the memoizer and is happens-before based.  It considers one memory
access happens before another with respect to the synchronization order
the memoizer records.  Sometimes a pair of instructions may appear to be a
race, when in fact their relative order does not alter a run.  For
instance, a write-write race is benign if both instructions write the same
value.  Similarly, a read-write race is benign if the value written by one
instruction does not affect the value read by another.  Our race detector
prunes these benign races.

Our detector also flags \emph{symbolic races}, the races that are
data-dependent on inputs.  Figure~\ref{fig:tern-symbolic-race} shows an example.
Both variables $i$ and $j$ are inputs, and the race occurs only when $i =
j$.  The risk of a symbolic races is that it may be absent in a
memoization run and thus skip detection, but show up nondeterministically
in a reuse run.  To detect symbolic races, our race detector queries the
underlying symbolic execution engine for pointer equality.  For example,
to detect the race in Figure~\ref{fig:tern-symbolic-race}, it would query the
underlying symbolic execution engine for the satisfiability of
$\&a[i]=\&a[j]$.  It flags a symbolic race if this constraint is satisfiable.
Once a symbolic race is flagged, \tern adds additional input constraints to
ensure that the race does not occur in reuse runs.  For
Figure~\ref{fig:tern-symbolic-race}, we would add $\&a[i]\neq \&a[j]$, which
simplifies to $i\neq j$.

Our race detector can detect all schedule races in a memoization run.  It
can also detect all symbolic races if developers correctly annotate all
data that affect synchronization operations and memory locations accessed.
If this assumption holds and our race detector reports no races in a
memoization run, \tern ensures that the memoized schedule can be
deterministically reused.


\subsection{Skipping Unnecessary Synchronizations}  \label{sec:tern-skip-waits}

When reusing a schedule, \tern enforces a total synchronization order
according to the schedule.  These \tern-enforced execution order constraints
are more stringent than the constraints enforced by the original
synchronizations in the program.  Thus, for speed, \tern can actually skip
these unnecessary synchronizations.  In our current implementation, we
skip \vv{sleep()}, \vv{usleep()}, and \vv{pthread\_barrier\_wait()}
because they are frequently used.  We
found that this optimization was quite effective and
even made programs run faster than nondeterministic execution
(\S\ref{sec:tern-overhead}).

\subsection{Simplifying Constraints} \label{sec:tern-simplify}

To reuse a schedule, \tern must check if the current input satisfies the
constraints of the schedule.  The overhead of this check depends on the
number of constraints, yet the set of constraints \tern collects may not
always be in simplified form.  That is, a subset of the constraints may
imply the entire set.  For example, consider a loop ``\vv{for(int
  i=0;i!=n;++i)}'' with a symbolic bound $n$.  When running this code with
$n=10$, we will collect a set of constraints $\{0 \neq n, 1 \neq n, ...,
10 = n\}$, but the last constraint alone implies the entire set.

To simplify constraints, \tern uses a greedy algorithm.  Given a set of
constraints $C$, it iterates through each constraint $c$, and checks if
$C/\{c\}$ implies $\{c\}$.  If so, it simply discards $c$.  Our
observation is that constraints collected later in a run tend to be more
compact than the earlier ones.  Thus, when pruning constraints, we start
from the ones collected earlier.  Although we could have used the
underlying symbolic execution engine to simplify constraints, it lacks
this domain knowledge and may perform poorly.

\subsection{Slicing Out Irrelevant Branches} \label{sec:tern-slicing}

A branch statement may observe a piece of symbolic data but perform no
synchronization operation in either branch.  The constraints collected
from this branch are unlikely to affect schedules.  If we include
irrelevant constraints in the input constraints of a schedule, we not only
increase constraint checking time, but also preclude legal reuses of the
schedule.

To address this problem, \tern employs a simple static analysis to
automatically prune likely irrelevant constraints.  At the heart of this
technique is a slicing analysis that identifies branch statements unlikely
to affect synchronization operations.  Specifically, given a branch
statement $s$, this analysis computes $s_d$, the immediate
post-dominator~\cite{aho:dragon:06} of $s$, and marks $s$ as irrelevant if
no synchronization operations are between $s$ and $s_d$.  Although simple,
this technique reduced constraint checking time significantly
(\S\ref{sec:tern-overhead}).  However, we note that our analysis is unsound
because it ignores data dependencies.  Thus, we plan to implement a sound
slicing algorithm~\cite{castro:bouncer} in our future work.

