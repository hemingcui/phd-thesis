\section{Leveraging \smt to Build Transparent Multithreaded State Machine Replication} \label{sec:replication}

In this section, we first introduce the background of state machine replication 
and its current limitations on building state machine replications for general 
multithreaded programs, and then present our design.

\subsection{Background} \label{sec:rep-intro}

Due to the trends of cloud computing, building higly-
available and fast applications have become critical. In order to 
provide high availability, the state machine replication (or SMR) approach has become 
popular. Todo: briefly introduce SMR use Paxos to totally order all requests. In order to
build fast services, people introduce read-only optimizations for read requests.

Unfortunately, despite much effort from academia and industry, it is still 
insufficient for software vendors to provide practical state machine 
replication service to general applications, because of two challenges. First, existing 
state machine replication techniques typically require developers to replicate 
a specific subset of program states (with APIs) instead of the whole program 
states, which requires strong distributed sytems expert knowledge, hard to 
maintain with the rest of the applications, and error prone 
(Todo: cite the MongoDB exmample). Second, existing SMR infrastructures assume all 
replicas always run the same schedule for the same input, pracitally restricing 
the number of running threads to be only one and preventing them fully leverage the 
power of the multi-core hardware.

Addressing the first challenge requires a general design of APIs for SMR. 
Todo: motivate people that we use design the interface at the socket API level.

Addressing the second challenge requires a systematic way of to ensure the same 
schedules. Todo: introduce \smt, which can greatly reduce the number of schedules for 
multithreaded programs.

This article made two major contributions towards building practical state-
machine replications for multithreaded programs. First, how to reach 
consensus on general network inputs (including input values and timings) 
across replicas. Second, how to perform read-only 
optimization for general applications, which is hard, because some 
semantically read only operations (such as get() in key-value store and GET 
in http servers) may modify states of server programs.

Our system is the first system on building practical state-machine 
replications for general multi-threaded programs. Todo: how it works: reach 
consensus on general socket operations, LD\_PRELOAD, transparent (do not need 
to annotate shared states in a program) replications for servers.

Introduce the fault-tolerance and performance features (guarantees) of our 
system.

Practical highlights of our system: evaluated a good range of popular server 
programs, ranging from web servers, data base servers, key-value stores, and 
popular utility programs. Todo: performance highlights, recovery highlights.

\subsection{\msmr: A Pracitcal SMR sytem for general multithreaded programs} \label{sec:rep-msmr}
This section first introduces the \msmr architecture, and then describes how it 
ensure consensus on socket APIs, and then presents our design on read-only 
optimization.

\subsubsection{\msmr architecture} \label{sec:rep-arch}

Figure XXX shows the \msmr architecture in each node. Each node starts with a proxy, 
which is a \paxos daemon (\S\ref{sec:rep-consensus}), and each proxy forks a child to execute an 
application (\eg, a web server) running with a \smt tool. The proxy has a logger module to 
persistently manage executed operations, and it also has a read optimizer (\S\ref{sec:rep-readonly})
module to perform read optimization. A checkpoint (\S\ref{sec:rep-checkpoint}) module sits on both 
application site and kernel site in order to checkpoint execution states of each application.

\subsubsection{Reaching consensus on socket APIs} \label{sec:rep-consensus}
The key goal of our consensus module is: ensure all replicas execute the same 
sequence of socket operations in the same total order, and each operation must 
be executed (or returned) at the same logical time. To achieve this goal, we 
leverage \paxos to performance the consensus on socket operations, and 
logical clocks are carried as value of each consensus instance. Therefore, our 
consensus module is transparent to \paxos logic and enjoy the same fault tolerance 
benefits as \paxos.

Todo: data format of our operations. Operation ID, arguments, logical clocks, etc.

We only need to support blocking socket operations at server side that depend on external 
network inputs. Below are the operations we hook and how we handle them:

\begin{itemize}
\item listen(). All replicas return from this call at the same logical clock.
  
\item accept(). All replicas return from this call at the same logical clock.

\item recv(), read(), and recvfrom(). All replicas return from this call at the same logical clock.

 \item select() and poll(). Make sure all replicas have the available set of file 
 descriptors. We ensure this invariant by keeping the start of select() at the same logical
 clock and end at the same logical clock, and bind all the recv() request with their select()
 function. (Todo: need better wording).

\end{itemize}

Todo: the logical clock prediction algorithm. One challenge: what if new requests 
come while the primay is still running existing requests, ho do we predict a 
feasible logical clocks? And how do we predict (and update/subtract) logical clocks for group 
operations such as select()?

\subsubsection{Read-only optimization} \label{sec:rep-readonly}
For speed, modern SMR systems introduce read-only optimization: for many applications such as web servers and key-value stores,
 most of read operations do not modify applcation states, and SMR systems process them rapidly in 
local replicas without reaching consensus for these operations. Todo: needs a 
carefuly definition of read-only requests, because we only have schedule hash 
and we can not monitor shared memory variables.

Unfortunately, in the multithreading settings, some read-only requests such as http GET requests may
modify the application's internal cache, potentially causing divergence of both application states and 
schedules on processing these requests.

In order to support read-only optimizations in \msmr, we leverage the performance critical 
section (a.k.a pcs) in \parrot~cite{parrot:sosp13}, so that we could process 
these read-only operations rapidly without needing consensus. Todo: also 
mention the client side design for identifying read-only requests.

In order to address the above challenge that read-only reqeusts may modify internal 
application cache and causing schedule divergence, we leverage a key 
insight: although the first few of them may modify application's internal states, this 
sequence tend to make the application finally converge to a stable state. Based 
on this insight, we could design an approach to soundly detect the application 
state changes by checking the schedule hash serving current request, and 
safely roll back to a 'soft' checkpoint if we detect state changes and 
deliver these first few read requests to the primary. Our approach can soundly 
detect application state changes (including even application internal cache 
expiration) that may affect schedules. And this approach enables our system 
to be very fast: run even faster than the single node un-replicated 
application.

Although this read-only optimization approach is simple and sound, it has to 
address a few challenges. First, although the internal cache modified by read-only 
requests may affect the schedules of read or write requests. Second, the 
soundness of this approach should not be weakened by corner case events in the 
distributed systems.

In order to address the first challenge (\ie, read-only requests may affect 
other read or write requests), our key approach is: maintain schedule hash for write 
requests. We consider all these four cases:

(1) The same (input) read requests affecting themselves. This is avoided by 
having the schedule hash for read-only requests, as mentioned above.

(2) Read requests affecting write requests. For each ``accept" message of a 
write request sent by the \paxos primary node, we attach the schedule hash (for 
the first operation, it is empty, and this has no conflict) of 
the last executed operation in the this ``accept" message with the ``committed" 
view stamp, so that all the replicas can compare this schedule hash with its 
own ones after executing each request. This carefuly design does not require 
the primary to execute the current request first, get the schedule hash, and 
then start consenses, because we attach the previous schedule hash. Once a 
replica executes a write request, and founds that the current schedule hash is 
different from the ones sent from the primary, current replica just rolls back 
to a soft checkpoint and then replays only requests that require consenses (the 
replica can safely ignore read-only requests). We expect this roll back is 
rare, because the application internal cache tends to be a per-input property 
and should rarely affect other inputs.

(3) Read requests affecting other read requests. This can also be detected by 
the schedule hash for each read request, because schedule hash is the unique ``stable" 
signature of each read request, and once some read requests are affected by 
other read requests, their schedule hash becomes different.

(4) Write affect read. For this case, we may need more than two read-only 
operations to be involved in consensus, but this is fine, as read-only requests 
are majority of requests and they tend to push the system to converge to a 
stable state.

One may ask, can we just simply maintain schedule hash for write requests and 
simply roll back when we see a divergence of schedule hash for each write 
request? This naive approach could work, if and only if our marking of read 
only requests are completely precise (\ie, it would never mark write request as 
read-only requests). Unfortunately, this case could not be completely avoided 
because human may make mistakes, and the self comparisons of read-only requests 
are the key to detect whether they are actually read-only requests (\eg, some 
requests marked as read-only may actually modify systems states everytime and 
their schedule hash may never converge).

To address the second challenges, we discuss our approach on three (Todo: more?) popular 
corner cases:

(1) Packet loss causing schedule hash to get lost. This won't occur, because 
for each node in \msmr, the consensus proxy and the application shares the same 
physical machine, and the schedule hash executed by the application is recorded 
persistently by us.

(2) Node crash. For this case, in the restart phase, we simply erase all 
schedule hash, because current in memory application state does not match the 
application memmory states implied in schedule hash any more. Note that 
schedule hash is just our hints, and it can be safely erased in any case 
without affecting soundness or correctness of our system.

(3) Network partition or \paxos message lost. In this case, we can do nothing 
special (but we can still serve requests, \eg, read-only requests), because 
later if the network gets back, our above schedule hash can detect all types of 
read/write conflicts and roll back; if the network never gets back, this node 
can not reach any consensus with other nodes and then won't execute any write 
requests.

%% One may ask, can we just maintain the schedule hash for the write requests 
%% only, and then just simply roll back when we see a divergence of the schedule 
%% hash? Yes, this is a correct design, but it may trigger lots of roll backs, 
%% because the first few read only requests may cause the logical clock  ??? Not 
%% really.


\subsection{Implementation} \label{sec:rep-impl}
TBD.

\subsubsection{Checkpointing and failure recovery} \label{sec:rep-checkpoint}
In order to recover a replica from failure or application conflicts caused by 
read only requests, we need to have a systematic checkpoint mechanisms for the applications.

In order to ensure both robustness against failures and speed over conflicts, 
\msmr designs two kinds of checkpoints: to handle node failures, a hard checkpoint saves current application 
state permanently to 
disk; to handle conflicts, a soft checkpoint saves current application state by 
simply forking a process (issue: can this fork clone all child threads?), and 
rolling back to a soft checkpoint just simply changes the forked process as 
current working process.

A hard checkpoint is expensive because of disk IO. In order to minimize its 
impact, we have a replica (instead of a primary that needs to serve requests 
and get back to client as soon as possible) to do a periodical (minutes or hours) checkpiont. This 
hard checkpoint operation is first handled as a \paxos consensus operation (the 
ID of this checkpoint is the last executed \paxos operation in current 
replica, and the location of the checkpoint is the replica's ID), and then performs a hard checkpoint.
Once any node in the distributed 
system is restarted, it simply checks the last checkpoint in the \paxos 
operation log and asks for a network transformation of the checkpoint, and 
then replays the following operations. Since node failures are rare, we expect 
this mechanism won't affect performance much. In the implementation level, We can have a dedicated
client in the system to periodical asks for hard checkpoints.

A soft checkpoint is invoked more frequently (\eg, in seconds) than a hard 
checkpoint, and it is just a local property for resolving conflicts (\ie, it will never 
be transmitted across nodes).

Currently our checkpoint for application involves four things: file systems, memory state,
network sockets, and CPU registers. For file systems, we use Dockers.
For memory state, we use virtual machine or hardware virtualization 
techniques. Network sockets can also easily checkpointed because the network 
sockets between the applications (\eg, servers) and our proxy are controled by 
us internally. CPU registers can also be saved.



\subsubsection{Handling nondeterministic operations} \label{sec:rep-nondet}
In reality, applications may call nondetermnistic operations, including 
``rand()" and ``gettimeofday()", and the return value of these functions may 
affect control flow and schedules of applications (\eg, the \apache uses 
``gettimeofday()" to check cache expiration). We use the same approach as that 
in PMP (todo: add citation) to address this problem: for each request, a \msmr roxy executes
this function multiple times (long enough) in advance and send the result list to all the replicas,
replicas just take the result from the list to serve the request from the 
application. For ``rand()", we acutally execute the ``srand()" and enforce the 
same seeds on all replicas.

\subsubsection{Maintaining systems resources} \label{sec:re-resource}
Systems resources such as file descriptors may need to be maintained by 
\msmr and we maintain their own mappings and return a consistent value to the 
return value of IO functions.

\subsubsection{Maintaining systems resources} \label{sec:rep-race}
We have a dedicated client to invoke a race detector on a replica node within our system, 
and we don't forward read-only requests for this replica. This detector is to 
practically remind develpers to fix and diagnose races.

\subsection{Evaluation plan} \label{sec:rep-eval}
Performance overhead with the single node multithreaded version.

Performance breakdown (analysis) of the consensus component and the read-only optimization component.

Race detection results.

Recovery scenarios and performance results.

Systems parameter sensitivity evaluation, including the periods of hard and soft checkpoints, etc.


\subsection{\msmr has broad applications} \label{sec:rep-apps}

This section describes several potential applications of \msmr.

\subsubsection{Fast and effective concurrency error detection} \label{sec:rep-races} 
TBD.

\subsubsection{Fast information flow tracking} \label{sec:rep-ift}
TBD.

\subsubsection{TBD} \label{sec:rep-apps-tbd}
TBD.

