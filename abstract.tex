Multithreaded programs have become pervasive and critical due to the
accelerating computational demand and the rise of the multi-core hardware.
Unfortunately, despite decades of research and engineering effort, these
programs are still notoriously difficult to get right, and they are plagued with
harmful concurrency bugs that can cause wrong outputs, program crashes, security
breaches, and so on. Our study reveals that a key reason of this difficulty is
that multithreaded programs have too many possible thread interleavings (or
schedules) at runtime, probably due to performance favor. Even given only a
single input, a program may run into excessive schedules, depending on such
factors as hardware timing and OS scheduling. Considering all inputs, the number
of schedules is even much greater. If we denote the schedule set of a
multithreaded program for all inputs as a ``haystack", finding a schedule that
contains concurrency bugs in this schedule set is just like finding a ``needle"
in a ``haystack", making understanding, testing, and analyzing of mulithreaded
programs extremely difficult.

In order to reduce the number of schedules for all inputs, we have studied the
relation between inputs and schedules of real-world programs, and made an
eye-opening discovery: many programs need only a small set of schedules to
efficiently process a wide range of inputs! Leveraging this discovery, we have
proposed a new idea called Stable Multi-Threading (StableMT) that reuses each
schedule on a wide range of inputs, greatly reducing the number of possible
schedules for all inputs. By greatly shrinking the ``haystack", StableMT makes
the ``needles" much easier to find and multithreaded programs much easier to get
right. In order to make StableMT real, we have built three StableMT systems,
\tern, \peregrine, and \parrot, with each addressing a distinct research
challenge. We have also quantitatively demonstrated that StableMT can benefit
existing reliability techniques, including: (1) making reproducing real-world
concurrency bugs much easier; (2) greatly increasing coverage of model checking,
a systematic testing technique, by many orders of magnitudes; and (3) greatly
improving precision of static program analysis, leading to several new harmful
data races detected in heavily-studied programs.

